SuperPoint 최적화
이 README는 SuperPoint 코드베이스의 성능, 메모리 사용량, 전반적인 효율성을 향상시키기 위해 적용된 최적화에 대한 문서를 제공합니다.

목차

TensorFlow 호환성
모델 아키텍처 최적화
공통 유틸리티 최적화
데이터셋 파이프라인 최적화
학습 프로세스 최적화
디스크립터 계산 최적화
메모리 사용량 최적화
추론 최적화

TensorFlow 호환성
모든 파일에서 TensorFlow 임포트를 표준화하여 호환성 보장:
pythonimport tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
더 이상 사용되지 않는 기능 업데이트:

tf.contrib.layers.l2_regularizer를 tf.keras.regularizers.l2로 교체
누락된 timeline 라이브러리를 처리하도록 프로파일링 코드 업데이트

모델 아키텍처 최적화
models/backbones/vgg.py의 VGG 백본 최적화:

블록 간 공통 매개변수 표준화
성능 향상을 위한 채널 차원 최적화
더 나은 모델 구성을 위한, 구조화된 변수 스코핑 추가

공통 유틸리티 최적화
models/utils.py의 비최대 억제(NMS) 구현 개선:

빈 감지 세트에 대한 조기 종료 추가
낮은 확률의 감지를 조기에 필터링하여 메모리 사용량 최적화
더 효율적인 상위 k개 선택 구현

데이터셋 파이프라인 최적화
datasets/base_dataset.py의 데이터 로딩 파이프라인 개선:

자주 사용하는 데이터에 대한 데이터셋 캐싱 추가
자동 배치 크기 최적화 구현
모델 실행과 데이터 전처리를 겹치게 하는 프리페칭 추가
최적의 버퍼 크기를 위한 TensorFlow의 자동 조정 기능 사용

학습 프로세스 최적화
models/base_model.py의 학습 루프 개선:

학습률 감소 스케줄링 추가
과적합을 방지하기 위한 조기 중단 구현
최고 모델 체크포인트 추가
검증 메트릭 로깅 개선
timeline을 사용할 수 없을 때 대체 옵션이 있는 강력한 프로파일링 추가

디스크립터 계산 최적화
models/super_point.py의 디스크립터 헤드 최적화:

계산량을 줄이기 위한 중간 채널 차원 감소
더 효율적인 리사이징 연산 사용
더 안정적인 디스크립터를 위한 L2 정규화 개선

메모리 사용량 최적화
experiment.py의 메모리 공간 감소:

모든 메모리를 미리 할당하지 않도록 GPU 메모리 증가 설정 추가
큰 배치 크기에 대한 경고 추가
제한된 메모리 시나리오를 위한 그래디언트 누적 시뮬레이션 구현

추론 최적화
models/magic_point.py의 모델 추론 최적화:

필요에 기반한 조건부 디스크립터 계산 구현
NMS 연산을 위한 효율적인 마스킹 추가
더 나은 특징 매칭을 위한 호모그래피 적응 최적화